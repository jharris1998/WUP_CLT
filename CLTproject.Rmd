---
title: "CLT_WUP"
author: "Jarrod Harris "
output: 
  html_document:
    number_sections: true
    toc: true
    toc_depth: 5
date: "`r Sys.Date()`"    
    
---

kkardashtemp  see code below

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
require(lattice)
```

```{r}
Homers_data <- read.csv(file="Homers_data.csv")

my1000 <- sample(Homers_data , size = 1000, replace=T)

```

```{r}

library(ggplot2)
sampleNumber = sample(1:10000, size = 1000)
library(dplyr)
my1000 <- Homers_data[sampleNumber, ]
names(my1000)
# Basic density
p <- ggplot(my1000, aes(x=kkardashtemp,col=sex)) + 
  geom_density()
p
# Add mean line
p+ geom_vline(aes(xintercept=mean(kkardashtemp)),
            color="blue", linetype="dashed", size=1)
```
```{r}
print(paste('mean = ', mean(my1000$kkardashtemp),' sd = ',sd(my1000$kkardashtemp)))
```

```{r}
numb=2
Hdata = Homers_data[sample(1:1000, size=numb*1000, replace=T),"kkardashtemp"]
mdata  <-matrix(Hdata,nrow=1000,ncol=numb)
x.avg <- apply(mdata,1,mean)
my1000$k2 = x.avg

p <- ggplot(my1000, aes(x=k2)) + 
  geom_density() 
p
```

# Add mean line
  geom_vline(aes(xintercept=mean(k2)),
            color="blue", linetype="dashed", size=1)
 
```{r}           
print(paste('mean = ', mean(my1000$k2),' sd = ',sd(my1000$k2)))
```

```{r}
numb = 9
Hdata = Homers_data[sample(1:1000,size=numb*1000, replace=T),"kkardashtemp"]
mdata  <-matrix(Hdata,nrow=1000,ncol=numb)
x.avg <- apply(mdata,1,mean)
my1000$k9 = x.avg


p <- ggplot(my1000, aes(x=k9),Col=sex) + 
  geom_density() +

  # Add mean line
 geom_vline(aes(xintercept=mean(k9)),
            color="blue", linetype="dashed", size=1)
```

```{r}
p + ggtitle("n = 9") +
  xlab("temperature") + ylab(" density")
```

```{r}           
print(paste('mean = ', mean(my1000$k9),' sd = ',sd(my1000$k9)))
```

The mean will always get close to 50 and the standard deviation is getting smaller. This makes sense since the dividing number in the standard deviation formula is getting bigger, when we predict using 41.38 as the sample standard deviation and use sqrt(9) as the sample size we see the predicted value to be 13.79333 and this is pretty close to the approximate value of 14 for the standard deviation.

```{r}
numb=16
Hdata = Homers_data[sample(1:1000, size=numb*1000, replace=T),"kkardashtemp"]
mdata <-matrix(Hdata,nrow=1000,ncol=numb)
x.avg <- apply(mdata,1,mean)
my1000$k16 = x.avg

p <- ggplot(my1000, aes(x=k16), (Col=sex))+
geom_density()

p + ggtitle("n = 16") +
xlab("temperature") + ylab("density")
```

```{r}
print(paste('mean = ', mean(my1000$k16),' sd = ',sd(my1000$k16)))
```

The mean will always get close to 50 but hovers around 49. The standard deviation is smaller being around 11 compared to the approximate value of n=9â€™s 14 standard deviation. Predicting the standard deviation value using sqrt(16) we get about 10.345 being relativley close to the approximate value of 11.

```{r}
numb=25
Hdata = Homers_data[sample(1:1000, size=numb*1000, replace=T),"kkardashtemp"]
mdata <-matrix(Hdata,nrow=1000,ncol=numb)
x.avg <- apply(mdata,1,mean)
my1000$k25 = x.avg

p <- ggplot(my1000, aes(x=k25), (Col=sex))+
geom_density()

p + ggtitle("n = 25") +
xlab("temperature") + ylab("density")
```

```{r}
print(paste('mean = ', mean(my1000$k25),' sd = ',sd(my1000$k25)))
```

The mean is still close to 50 and the standard deviation has decreased to be approximately 8. A predicted standard deviation using sqrt(25) gives us about 8.276 which is still close for the approximate value of 8. The graph is starting to look more similar on the sides but the tip at around 50 does stand out more often with different data.

```{r}
numb=36
Hdata = Homers_data[sample(1:1000, size=numb*1000, replace=T),"kkardashtemp"]
mdata <-matrix(Hdata,nrow=1000,ncol=numb)
x.avg <- apply(mdata,1,mean)
my1000$k36 = x.avg

p <- ggplot(my1000, aes(x=k36), (Col=sex))+
geom_density()

p + ggtitle("n = 36") +
xlab("temperature") + ylab("density")
```

```{r}
print(paste('mean = ', mean(my1000$k36),' sd = ',sd(my1000$k36)))
```

## We expect the sample mean to be close to population and the standev to get smaller by the ratio of one to the sample size. In this case 1/sqrt(2)

### There are 3 peaks in the density plot. You pick two people you can get MM,MF.FM,or FF. these are all equally likey so the little peak on left is all the FF's while the little peak on the right is all the MM's so the big one in the middle is both the MF and FM in the same bag so-to-speak.  





print(paste('mean = ', mean(my1000$k9),' sd = ',sd(my1000$k9)))
```

From my observation when you change the number and knit it gives a different graph. It also gives me the value of the standard deviation. It was 41.7267551709583 the first time and I expect this number to be half of the k2.(print(paste( " sd = ",sd(my1000$k9))) is less than half of the k2.







### In this case the stdev was cut in half because the sample size was four. This is what the central limit theorem says. There are also 5 peaks. They go from FFFF,to FFFM, to FFMM to FMMM and finally MMMM.

# Now finish by adding blocks with numb being 9, then 16, 25, and 36. be sure to mention how the standard deviation progresses as the sample size changes,


After viewing the test it shows that every time its knitted its give a result of a different graph. Also it gives me the value of standard deviation. It was  41.9351221945695 the first time and I expect this number to be half than that. It was less than half it's 14.0238939987023